{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13890690,"sourceType":"datasetVersion","datasetId":8849590}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q \"protobuf==3.20.3\"\n\n# ============================================================\n# 0. INSTALL + IMPORTS\n# ============================================================\n!pip install -q transformers datasets sentencepiece accelerate\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom transformers import (\n    T5ForConditionalGeneration,\n    AutoTokenizer,\n    DataCollatorForSeq2Seq,\n    Seq2SeqTrainingArguments,\n    Seq2SeqTrainer,\n)\n\nfrom datasets import load_dataset\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# ============================================================\n# 2. LOAD DATASET\n# ============================================================\nraw = load_dataset(\"ScaDSAI/ParaDeHate\")[\"train\"]\ndf = raw.train_test_split(test_size=0.1, seed=42)\n\ntrain_ds = df[\"train\"]\ntest_ds  = df[\"test\"]\n\nSRC_COL = \"Original Text\"\nTGT_COL = \"Converted Text\"\n\n# ============================================\n# 1. LOAD TEACHER AND STUDENT\n# ============================================\nteacher_name = \"/kaggle/input/distilbart-t5-finetuned/t5-base_finetuned\"   # <-- your path\nstudent_name = \"t5-small\"\n\nteacher_tok  = AutoTokenizer.from_pretrained(teacher_name)\nstudent_tok  = AutoTokenizer.from_pretrained(student_name)\n\nteacher_model = T5ForConditionalGeneration.from_pretrained(teacher_name).to(DEVICE)\nstudent_model = T5ForConditionalGeneration.from_pretrained(student_name).to(DEVICE)\n\nteacher_model.eval()\nfor p in teacher_model.parameters():\n    p.requires_grad = False\n\n\n# ============================================\n# 2. PREPROCESS FUNCTION\n# ============================================\n\nPREFIX = \"detoxify: \"\nMAX_SRC = 96\nMAX_TGT = 96\n\n\ndef preprocess(batch):\n    src = [PREFIX + x for x in batch[SRC_COL]]\n    tgt = batch[TGT_COL]\n\n    # ----------------------------- STUDENT -----------------------------\n    s_in = student_tok(\n        src,\n        truncation=True,\n        max_length=MAX_SRC,\n        padding=\"max_length\"\n    )\n\n    s_out = student_tok(\n        tgt,\n        truncation=True,\n        max_length=MAX_TGT,\n        padding=\"max_length\"\n    )\n\n    labels_s = [\n        [(tok if tok != student_tok.pad_token_id else -100) for tok in seq]\n        for seq in s_out[\"input_ids\"]\n    ]\n\n    # ----------------------------- TEACHER -----------------------------\n    t_in = teacher_tok(\n        src,\n        truncation=True,\n        max_length=MAX_SRC,\n        padding=\"max_length\"\n    )\n\n    t_out = teacher_tok(\n        tgt,\n        truncation=True,\n        max_length=MAX_TGT,\n        padding=\"max_length\"\n    )\n\n    labels_t = [\n        [(tok if tok != teacher_tok.pad_token_id else -100) for tok in seq]\n        for seq in t_out[\"input_ids\"]\n    ]\n\n    return {\n        \"input_ids_s\": s_in[\"input_ids\"],\n        \"attention_mask_s\": s_in[\"attention_mask\"],\n        \"labels_s\": labels_s,\n\n        \"input_ids_t\": t_in[\"input_ids\"],\n        \"attention_mask_t\": t_in[\"attention_mask\"],\n        \"labels_t\": labels_t,\n    }\n\n\n# ============================================================\n# 3. APPLY PREPROCESS\n# ============================================================\ntrain_tok = train_ds.map(\n    preprocess,\n    batched=True,\n    remove_columns=train_ds.column_names\n)\n\ntest_tok = test_ds.map(\n    preprocess,\n    batched=True,\n    remove_columns=test_ds.column_names\n)\n\n\n# ============================================================\n# 4. COLLATOR (NO PADDING HERE — FIXED)\n# ============================================================\nclass STCollator:\n    def __init__(self, student_model):\n        self.student_model = student_model\n\n    def __call__(self, batch):\n\n        input_ids = torch.tensor([b[\"input_ids_s\"] for b in batch], dtype=torch.long)\n        attention_mask = torch.tensor([b[\"attention_mask_s\"] for b in batch], dtype=torch.long)\n        labels = torch.tensor([b[\"labels_s\"] for b in batch], dtype=torch.long)\n\n        decoder_input_ids = self.student_model._shift_right(labels)\n\n        input_ids_t = torch.tensor([b[\"input_ids_t\"] for b in batch], dtype=torch.long)\n        attention_mask_t = torch.tensor([b[\"attention_mask_t\"] for b in batch], dtype=torch.long)\n        labels_t = torch.tensor([b[\"labels_t\"] for b in batch], dtype=torch.long)\n\n        return {\n            \"input_ids\": input_ids,\n            \"attention_mask\": attention_mask,\n            \"labels\": labels,\n            \"decoder_input_ids\": decoder_input_ids,\n\n            \"input_ids_t\": input_ids_t,\n            \"attention_mask_t\": attention_mask_t,\n            \"labels_t\": labels_t,\n        }\n\ncollator = STCollator(student_model)\n\n\n# ============================================================\n# 5. DISTILLATION MODEL (CORRECT KL + MASKING)\n# ============================================================\nclass DistillT5(nn.Module):\n    def __init__(self, student, teacher, T=2.0, kl_weight=0.7):\n        super().__init__()\n        self.student = student\n        self.teacher = teacher\n        self.T = T\n        self.kl_weight = kl_weight\n\n    def forward(\n        self,\n        input_ids,\n        attention_mask,\n        labels,\n        decoder_input_ids,\n        input_ids_t,\n        attention_mask_t,\n        labels_t,\n    ):\n\n        # ---------------- TEACHER ----------------\n        with torch.no_grad():\n            t_out = self.teacher(\n                input_ids=input_ids_t,\n                attention_mask=attention_mask_t,\n                decoder_input_ids=decoder_input_ids,\n                return_dict=True,\n            )\n            t_probs = F.softmax(t_out.logits / self.T, dim=-1)\n\n        # ---------------- STUDENT ----------------\n        s_out = self.student(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            decoder_input_ids=decoder_input_ids,\n            labels=labels,\n            return_dict=True,\n        )\n\n        ce = s_out.loss\n        s_logits = s_out.logits / self.T\n        s_log_probs = F.log_softmax(s_logits, dim=-1)\n\n        # mask padding\n        mask = (labels != -100).unsqueeze(-1).expand_as(s_logits)\n\n        kl = F.kl_div(\n            s_log_probs[mask],\n            t_probs[mask],\n            reduction=\"batchmean\",\n        ) * (self.T ** 2)\n\n        return {\"loss\": ce + self.kl_weight * kl}\n\nmodel = DistillT5(student_model, teacher_model)\n\n\n# ============================================================\n# 6. TRAINER\n# ============================================================\nclass KDTrainer(Seq2SeqTrainer):\n    def compute_loss(self, model, inputs, return_outputs=False, *args, **kwargs):\n        return model(**inputs)[\"loss\"]\n\n\n# ============================================================\n# 7. TRAINING ARGS\n# ============================================================\nargs = Seq2SeqTrainingArguments(\n    output_dir=\"./t5-small-distilled\",\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=4,\n    gradient_accumulation_steps=2,\n    learning_rate=2e-4,\n    num_train_epochs=3,\n    fp16=torch.cuda.is_available(),\n    logging_steps=50,\n    save_strategy=\"no\",\n    remove_unused_columns=False,\n    report_to=\"none\",\n    label_names=[\"labels\", \"labels_t\"],\n)\n\n\n# ============================================================\n# 8. TRAIN\n# ============================================================\ntrainer = KDTrainer(\n    model=model,\n    args=args,\n    train_dataset=train_tok,\n    eval_dataset=test_tok,\n    data_collator=collator,\n    tokenizer=student_tok,\n)\n\ntrainer.train()\n\n# ============================================================\n# 8. GENERATION FUNCTION\n# ============================================================\n\nstudent_model.save_pretrained(\"t5-small-distilled\")\nstudent_tok.save_pretrained(\"t5-small-distilled\")\n\nstudent_model = T5ForConditionalGeneration.from_pretrained(\"t5-small-distilled\").to(DEVICE)\nstudent_model.eval()\n\nBAD_PHRASES = [\"Click here\", \"For more information\", \"Click to read\", \"Read more\", \"Visit\", \"Learn more\"]\nbad_ids = [student_tok(b, add_special_tokens=False)[\"input_ids\"] for b in BAD_PHRASES]\n\ndef generate(text):\n    # if a single string is given, make it a list\n    single = False\n    if isinstance(text, str):\n        text = [text]\n        single = True\n\n    preds = []\n    for t in text:\n        enc = student_tok(PREFIX + t, return_tensors=\"pt\").to(DEVICE)\n        out = student_model.generate(\n            **enc,\n            max_length=96,\n            min_length=6,\n            num_beams=4,\n            length_penalty=0.8,\n            no_repeat_ngram_size=3,\n            early_stopping=True,\n            bad_words_ids=bad_ids,\n            pad_token_id=student_tok.pad_token_id,\n            eos_token_id=student_tok.eos_token_id,\n        )\n        preds.append(student_tok.decode(out[0], skip_special_tokens=True))\n\n    # return string if single input, otherwise list\n    return preds[0] if single else preds\n\n\nsample_texts = [\n    \"You are so stupid and annoying.\",\n    \"I hate you. Don't ever talk to me again.\",\n    \"This is the worst idea ever.\",\n    \"Shut up bro you know nothing.\",\n    \"Why are you acting like an idiot?\",\n    \"You are a stupid piece of trash.\",\n]\n\nprint(\"=== SAMPLE DETOX OUTPUTS ===\\n\")\nfor t in sample_texts:\n    print(\"Input:\", t)\n    print(\"Output:\", generate(t))\n    print()\n\n# ============================================================\n# 9. METRICS\n# ============================================================\n\nprint(\"Generating predictions...\")\ntest_src = list(test_ds[SRC_COL])\ntest_ref = list(test_ds[TGT_COL])\npreds = generate(test_src)\n\n!pip install -U evaluate bert-score\nimport evaluate, bert_score\n\nprint(\"Computing BERTScore...\")\nP, R, F1 = bert_score.score(preds, test_src, lang=\"en\", rescale_with_baseline=True)\nbert_f1 = F1.cpu().tolist()\n\n# -------- Style model --------\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nstyle_tok = AutoTokenizer.from_pretrained(\"unitary/toxic-bert\")\nstyle_clf = AutoModelForSequenceClassification.from_pretrained(\"unitary/toxic-bert\").to(DEVICE)\nstyle_clf.eval()\n\ndef style_score(texts):\n    scores = []\n    with torch.no_grad():\n        for i in range(0, len(texts), 16):\n            batch = texts[i:i+16]\n            enc = style_tok(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=256).to(DEVICE)\n            out = style_clf(**enc)\n            probs = out.logits.softmax(-1)[:, 1]   # toxic prob\n            scores.extend((1 - probs).cpu().tolist())\n    return scores\n\nstyle_s = style_score(preds)\n\n# -------- GPT-2 Fluency --------\nfrom transformers import GPT2TokenizerFast, GPT2LMHeadModel\ngpt_tok = GPT2TokenizerFast.from_pretrained(\"gpt2\")\ngpt = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(DEVICE)\ngpt_tok.pad_token = gpt_tok.eos_token\ngpt.config.pad_token_id = gpt_tok.pad_token_id\ngpt.eval()\n\ndef fluency(texts):\n    fs = []\n    with torch.no_grad():\n        for i in range(0, len(texts), 8):\n            batch = texts[i:i+8]\n            enc = gpt_tok(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(DEVICE)\n            loss = gpt(**enc, labels=enc[\"input_ids\"]).loss\n            ppl = torch.exp(loss)\n            fs += [1 / ppl.item()] * len(batch)\n    return fs\n\nflu_s = fluency(preds)\n\n\n# ============================================================\n# 10. SAVE RESULTS\n# ============================================================\n\nimport pandas as pd\n\nout = pd.DataFrame({\n    \"original_text\": test_src,\n    \"gold_detoxified\": test_ref,\n    \"student_output\": preds,\n    \"content_preservation\": bert_f1,\n    \"style_score\": style_s,\n    \"fluency\": flu_s,\n})\n\npath = \"./t5small_distilled_results.csv\"\nout.to_csv(path, index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T06:40:33.046704Z","iopub.execute_input":"2025-12-03T06:40:33.047016Z","iopub.status.idle":"2025-12-03T07:06:39.419669Z","shell.execute_reply.started":"2025-12-03T06:40:33.046995Z","shell.execute_reply":"2025-12-03T07:06:39.419012Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13427c0e8d0f47ac80319a98c9eb8d0a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02a49f30b6414f64b9e27e8d6f2226fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de909d4a85b8483cac8574cfab4179b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9770b1017d684bb0847dba2fdcb00f82"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"446a1df5ab734916a33eb1c82ed5507e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00e2c86b3358460aa97c4ed20fb3910d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/7448 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a53f8b8a11a4bc3b72b04f4d5b7b282"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/828 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a14d4f789e014f9b904ad054d3a30397"}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_47/2600248079.py:255: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `KDTrainer.__init__`. Use `processing_class` instead.\n  trainer = KDTrainer(\nPassing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1398' max='1398' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1398/1398 18:43, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>2.450400</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>2.107200</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>1.999200</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>1.956100</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>1.911200</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>1.872800</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>1.867800</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>1.892900</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>1.836900</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>1.767200</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>1.767000</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>1.689100</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>1.721100</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>1.693700</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>1.696900</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>1.726400</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>1.728200</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>1.707400</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>1.687400</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>1.633100</td>\n    </tr>\n    <tr>\n      <td>1050</td>\n      <td>1.628800</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>1.609800</td>\n    </tr>\n    <tr>\n      <td>1150</td>\n      <td>1.659100</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>1.618500</td>\n    </tr>\n    <tr>\n      <td>1250</td>\n      <td>1.644500</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>1.603400</td>\n    </tr>\n    <tr>\n      <td>1350</td>\n      <td>1.595600</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"=== SAMPLE DETOX OUTPUTS ===\n\nInput: You are so stupid and annoying.\nOutput: You are so upset and annoying.\n\nInput: I hate you. Don't ever talk to me again.\nOutput: I dislike you. Don't hesitate to talk to me again.\n\nInput: This is the worst idea ever.\nOutput: This is the worst idea ever.\n\nInput: Shut up bro you know nothing.\nOutput: Shut up, bro, you know nothing.\n\nInput: Why are you acting like an idiot?\nOutput: Why are you acting like an idiot?\n\nInput: You are a stupid piece of trash.\nOutput: You are a foolish person.\n\nGenerating predictions...\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\nCollecting bert-score\n  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.4.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.5)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.18)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.10.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.36.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\nRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.6.0+cu124)\nRequirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from bert-score) (4.53.3)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from bert-score) (3.7.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.20.0)\nRequirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (22.0.0)\nRequirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (0.28.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.10.5)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert-score) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (2025.11.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.5.3)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (4.59.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.4.8)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (11.3.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (3.0.9)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (4.11.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.0.0->evaluate) (0.16.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.3)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1.0.0->datasets>=2.0.0->evaluate) (1.3.1)\nDownloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate, bert-score\nSuccessfully installed bert-score-0.3.13 evaluate-0.4.6\nComputing BERTScore...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"565eb0264c644be4980fd0c77265f4b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"194882a72cf7415ba67e8e19af1bf280"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb905160d4ec495d9ce26cbcb925997a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8a221970689453e9e75b73660b314e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66c8742cf24646b9b76d4e60782f5e7c"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6273fe13cd04835bbef8b3370ddf3ae"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/174 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"951815b34bb24bd9ac7c90462c2f57d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/811 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f68f633bd2641b5a2bba7a352fc4fb8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67ddcb9ba7454ecca42cc887cd8174cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5032a365898b44a999432cffabbb3e05"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b3a5277d7af4547923db20338c8877e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2be790dc63fe49079eca48b50066bd5d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8388eefd512140139a04539dacfbd009"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e438f661a1a4a9f974810e1fe96fea0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ef2ab11b2a64eb29dfee60793fcc1bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a78ec2c7c16b4334afe6328c3640528f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4cb705780e54484985b82959a8692167"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ffd04951ce44ebaa42937869b157c90"}},"metadata":{}},{"name":"stderr","text":"`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"print(\"Student total params:\", student_model.num_parameters())\nprint(\"Student trainable params:\", student_model.num_parameters(only_trainable=True))\n\nprint(\"Teacher total params:\", teacher_model.num_parameters())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T07:21:10.892655Z","iopub.execute_input":"2025-12-03T07:21:10.893522Z","iopub.status.idle":"2025-12-03T07:21:10.900432Z","shell.execute_reply.started":"2025-12-03T07:21:10.893495Z","shell.execute_reply":"2025-12-03T07:21:10.899705Z"}},"outputs":[{"name":"stdout","text":"Student total params: 60506624\nStudent trainable params: 60506624\nTeacher total params: 222903552\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/working/t5small_distilled_results.csv')\nprint(f\"Style Accuracy: {df['style_score'].mean():.3f}\")\nprint(f\"Content Preservation: {df['content_preservation'].mean():.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T07:22:48.685610Z","iopub.execute_input":"2025-12-03T07:22:48.686505Z","iopub.status.idle":"2025-12-03T07:22:48.705731Z","shell.execute_reply.started":"2025-12-03T07:22:48.686474Z","shell.execute_reply":"2025-12-03T07:22:48.704966Z"}},"outputs":[{"name":"stdout","text":"Style Accuracy: 0.978\nContent Preservation: 0.678\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}